{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Import Package"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_set_base_path = \"../input/cat-and-dog/training_set/training_set/\"\nvalidation_set_base_path = \"../input/cat-and-dog/test_set/test_set/\"\n\ntraining_cat_path = training_set_base_path + \"cats\"\ntraining_dog_path = training_set_base_path + \"dogs\"\nvalidation_cat_path = validation_set_base_path + \"cats\"\nvalidation_dog_path = validation_set_base_path + \"dogs\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of training images: \", len(os.listdir(training_cat_path)) + len(os.listdir(training_dog_path)))\nprint(\"Number of validation images: \", len(os.listdir(validation_cat_path)) + len(os.listdir(validation_dog_path)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create ImageDataGenerator for Training without Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_generator = training_gen.flow_from_directory(directory=training_set_base_path,\n                                                      target_size=(400, 400),\n                                                      class_mode=\"categorical\",\n                                                      batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create ImageDataGenerator for Training with Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_gen_aug = keras.preprocessing.image.ImageDataGenerator(rescale=1/255,\n                                                                rotation_range=90,\n                                                                width_shift_range=0.2,\n                                                                height_shift_range=0.2,\n                                                                shear_range=0.2,\n                                                                zoom_range=0.2,\n                                                                fill_mode=\"nearest\",\n                                                                horizontal_flip=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_generator_aug = training_gen_aug.flow_from_directory(directory=training_set_base_path,\n                                                      target_size=(400, 400),\n                                                      class_mode=\"categorical\",\n                                                      batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create ImageDataGenerator for Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_generator = validation_gen.flow_from_directory(directory=validation_set_base_path,\n                                                          target_size=(400, 400),\n                                                          class_mode=\"categorical\",\n                                                          batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Model"},{"metadata":{},"cell_type":"markdown","source":"### Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = keras.layers.Input(shape=(400, 400, 3))\nx = keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu)(inputs)\nx = keras.layers.MaxPooling2D(pool_size=2)(x)\nx = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu)(x)\nx = keras.layers.MaxPooling2D(pool_size=2)(x)\nx = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu)(x)\nx = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu)(x)\nx = keras.layers.MaxPooling2D(pool_size=2)(x)\nx = keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu)(x)\nx = keras.layers.MaxPooling2D(pool_size=2)(x)\nx = keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu)(x)\nx = keras.layers.MaxPooling2D(pool_size=2)(x)\nx = keras.layers.Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu)(x)\nx = keras.layers.MaxPooling2D(pool_size=2)(x)\nx = keras.layers.Flatten()(x)\nx = keras.layers.Dense(units=128, activation=tf.nn.relu)(x)\nx = keras.layers.Dense(units=64, activation=tf.nn.relu)(x)\nx = keras.layers.Dense(units=32, activation=tf.nn.relu)(x)\nx = keras.layers.Dense(units=16, activation=tf.nn.relu)(x)\noutputs = keras.layers.Dense(units=2, activation=tf.nn.softmax)(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.Model(inputs=inputs, outputs=outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compilation"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Callback"},{"metadata":{"trusted":true},"cell_type":"code","source":"pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"initial_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Model with Non-Augmented Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=training_generator,\n          epochs=200,\n          steps_per_epoch=64,\n          validation_data=validation_generator,\n          validation_steps=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"history.json\", \"w\") as file:\n    json.dump(history.history, file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Model with Augmented Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(\"initial_model.h5\")\nhistory_aug = model.fit(x=training_generator_aug,\n          epochs=200,\n          steps_per_epoch=64,\n          validation_data=validation_generator,\n          validation_steps=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"history_aug.json\", \"w\") as file:\n    json.dump(history_aug.history, file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compare Two Training Process"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"history.json\", 'r') as file:\n    data = file.read()\n\nhistory = json.loads(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"history_aug.json\", 'r') as file:\n    data = file.read()\n\nhistory_aug = json.loads(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_acc = history[\"acc\"]\ntraining_val_acc = history[\"val_acc\"]\naug_training_acc = history_aug[\"acc\"]\naug_training_val_acc = history_aug[\"val_acc\"]\nepochs = list(range(len(training_acc)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(epochs, training_acc, 'bo', label=\"Training Acc\")\nplt.plot(epochs, training_val_acc, 'b', label=\"Validation Acc\")\nplt.title(\"Training Acc vs Validation Acc without Augmentation\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(epochs, aug_training_acc, 'bo', label=\"Training Acc\")\nplt.plot(epochs, aug_training_val_acc, 'b', label=\"Validation Acc\")\nplt.title(\"Training Acc vs Validation Acc with Augmentation\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}